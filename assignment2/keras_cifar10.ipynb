{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val:  (1000, 3, 32, 32)\n",
      "X_train:  (49000, 3, 32, 32)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "y_train:  (49000,)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "\n",
    "# load cifar10 data\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split and normalize data\n",
    "X_val, y_val = data['X_val'], data['y_val']\n",
    "X_train, y_train = data['X_train'], data['y_train']\n",
    "X_test, y_test = data['X_test'], data['y_test']\n",
    "\n",
    "# X_train /= 255.\n",
    "# X_val /= 255.\n",
    "# X_test /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 1 hot encode labels\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_val = to_categorical(y_val, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build network\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "def my_init(shape, dtype=None):\n",
    "    weight_scale = 1e-3\n",
    "    return weight_scale * np.random.randn(*shape).astype(dtype)\n",
    "\n",
    "keras.backend.set_image_data_format('channels_first')\n",
    "conv_kwargs = {'filters': 32, 'kernel_size': 3, \n",
    "               'padding': 'same', 'kernel_initializer': my_init}\n",
    "batch_kwargs = {'momentum': 0.9,\n",
    "                'epsilon': 1e-5, 'moving_variance_initializer': 'zeros'}\n",
    "\n",
    "shape = X_train.shape[1:]\n",
    "model.add(Conv2D(input_shape=shape, **conv_kwargs))\n",
    "model.add(BatchNormalization(axis=1, **batch_kwargs))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(**conv_kwargs))\n",
    "model.add(BatchNormalization(axis=1, **batch_kwargs))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(**conv_kwargs))\n",
    "model.add(BatchNormalization(axis=1, **batch_kwargs))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(**conv_kwargs))\n",
    "model.add(BatchNormalization(axis=1, **batch_kwargs))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, kernel_initializer=my_init))\n",
    "model.add(BatchNormalization(**batch_kwargs))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=my_init))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set optimizer\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "optim = Adam(decay=5e-3)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "49000/49000 [==============================] - 179s - loss: 1.2357 - acc: 0.5528 - val_loss: 0.9443 - val_acc: 0.6600\n",
      "Epoch 2/10\n",
      "49000/49000 [==============================] - 177s - loss: 0.7886 - acc: 0.7225 - val_loss: 0.7566 - val_acc: 0.7410\n",
      "Epoch 3/10\n",
      "49000/49000 [==============================] - 177s - loss: 0.6106 - acc: 0.7872 - val_loss: 0.6373 - val_acc: 0.7770\n",
      "Epoch 4/10\n",
      "49000/49000 [==============================] - 177s - loss: 0.4816 - acc: 0.8329 - val_loss: 0.6384 - val_acc: 0.7860\n",
      "Epoch 5/10\n",
      "49000/49000 [==============================] - 177s - loss: 0.3747 - acc: 0.8716 - val_loss: 0.6196 - val_acc: 0.7810\n",
      "Epoch 6/10\n",
      "49000/49000 [==============================] - 177s - loss: 0.2725 - acc: 0.9097 - val_loss: 0.6220 - val_acc: 0.8040\n",
      "Epoch 7/10\n",
      "49000/49000 [==============================] - 177s - loss: 0.1894 - acc: 0.9389 - val_loss: 0.6751 - val_acc: 0.7820\n",
      "Epoch 8/10\n",
      "49000/49000 [==============================] - 177s - loss: 0.1310 - acc: 0.9597 - val_loss: 0.6610 - val_acc: 0.8150\n",
      "Epoch 9/10\n",
      "49000/49000 [==============================] - 177s - loss: 0.0894 - acc: 0.9741 - val_loss: 0.7691 - val_acc: 0.7910\n",
      "Epoch 10/10\n",
      "49000/49000 [==============================] - 177s - loss: 0.0662 - acc: 0.9821 - val_loss: 0.8136 - val_acc: 0.7910\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=100, epochs=10,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_acc = np.mean(y_pred == y_test)\n",
    "print 'Test Accuracy: {}'.format(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
