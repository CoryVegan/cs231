{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val:  (1000, 3, 32, 32)\n",
      "X_train:  (49000, 3, 32, 32)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "y_train:  (49000,)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "\n",
    "# load cifar10 data\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split and normalize data\n",
    "X_val, y_val = data['X_val'], data['y_val']\n",
    "X_train, y_train = data['X_train'], data['y_train']\n",
    "X_test, y_test = data['X_test'], data['y_test']\n",
    "\n",
    "# X_train /= 255.\n",
    "# X_val /= 255.\n",
    "# X_test /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 1 hot encode labels\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_val = to_categorical(y_val, num_classes=10)\n",
    "y_test = to_categorical(y_val, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conv -> Batch -> Relu -> Conv -> Batch -> Relu -> Pool -> x 2\n",
    "# Conv -> Batch -> Relu -> Conv -> Batch -> Relu -> Conv -> Batch -> Relu -> Pool -> x2\n",
    "# Affine - > Affine -> Softmax\n",
    "\n",
    "# Windows were all 3x3, stride 1.\n",
    "# Pooling were all 2x2 max.\n",
    "\n",
    "# Total conv layers 10 with number of filters - 32, 32, 64, 64, 128, 128, 128, 196, 196, 196.\n",
    "# Affine layers had 500 hidden dims.\n",
    "\n",
    "# conv-relu-conv-relu-pool x 2\n",
    "# affine-softmax\n",
    "# lrf's are all 3x3, stride 1\n",
    "# pooling are all 2x2 max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build network\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "def my_init(shape, dtype=None):\n",
    "    weight_scale = 1e-3\n",
    "    return weight_scale * np.random.randn(*shape).astype(dtype)\n",
    "\n",
    "keras.backend.set_image_data_format('channels_first')\n",
    "conv_kwargs = {'filters': 32, 'kernel_size': 3, \n",
    "               'padding': 'same', 'kernel_initializer': my_init}\n",
    "batch_kwargs = {'momentum': 0.9,\n",
    "                'epsilon': 1e-5, 'moving_variance_initializer': 'zeros'}\n",
    "\n",
    "shape = X_train.shape[1:]\n",
    "model.add(Conv2D(input_shape=shape, **conv_kwargs))\n",
    "model.add(BatchNormalization(axis=1, **batch_kwargs))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(**conv_kwargs))\n",
    "model.add(BatchNormalization(axis=1, **batch_kwargs))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(**conv_kwargs))\n",
    "model.add(BatchNormalization(axis=1, **batch_kwargs))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(**conv_kwargs))\n",
    "model.add(BatchNormalization(axis=1, **batch_kwargs))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, kernel_initializer=my_init))\n",
    "model.add(BatchNormalization(**batch_kwargs))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=my_init))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set optimizer\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "49000/49000 [==============================] - 2221s - loss: 1.2195 - acc: 0.5600 - val_loss: 0.9217 - val_acc: 0.6720\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=100, epochs=1,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
